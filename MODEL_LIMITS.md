# 模型 Token 限制参考

本文档列出了常见 AI 模型的 token 限制，帮助你正确配置「最大 Tokens」参数。

## ⚠️ 重要说明

- **总 token 数 = 输入 tokens + 输出 tokens**
- 配置时需要考虑输入内容的长度，为输出预留足够空间
- 建议设置的「最大 Tokens」不要超过模型最大限制的 50-70%

## 📊 常见模型限制

### OpenAI 模型

| 模型 | 总限制 | 建议配置 |
|------|--------|----------|
| gpt-3.5-turbo | 4,096 | 2,000 |
| gpt-3.5-turbo-16k | 16,384 | 8,000 |
| gpt-4 | 8,192 | 4,000 |
| gpt-4-32k | 32,768 | 16,000 |
| gpt-4-turbo | 128,000 | 64,000 |
| gpt-4o | 128,000 | 64,000 |

### Anthropic Claude 模型

| 模型 | 总限制 | 建议配置 |
|------|--------|----------|
| claude-3-haiku | 200,000 | 100,000 |
| claude-3-sonnet | 200,000 | 100,000 |
| claude-3-opus | 200,000 | 100,000 |
| claude-3.5-sonnet | 200,000 | 100,000 |

### Google Gemini 模型

| 模型 | 总限制 | 建议配置 |
|------|--------|----------|
| gemini-pro | 32,768 | 16,000 |
| gemini-1.5-pro | 1,048,576 | 500,000 |
| gemini-1.5-flash | 1,048,576 | 500,000 |

### 其他模型

| 模型 | 总限制 | 建议配置 |
|------|--------|----------|
| deepseek-chat | 32,768 | 16,000 |
| qwen-turbo | 8,192 | 4,000 |
| qwen-plus | 32,768 | 16,000 |
| yi-large | 32,768 | 16,000 |

### 本地部署模型

| 模型 | 总限制 | 建议配置 |
|------|--------|----------|
| Llama 2 | 4,096 | 2,000 |
| Llama 3 | 8,192 | 4,000 |
| Mistral 7B | 8,192 | 4,000 |
| Mixtral 8x7B | 32,768 | 16,000 |

## 💡 配置建议

### 1. 短文本解释（默认场景）
```
最大 Tokens: 2,000 - 4,000
适用场景: 解释段落、句子、专业术语
```

### 2. 长文本解释
```
最大 Tokens: 8,000 - 16,000
适用场景: 解释整篇文章、长文档
```

### 3. 深度对话
```
最大 Tokens: 16,000+
适用场景: 需要长时间上下文对话、详细分析
```

## 🔍 如何选择合适的值

1. **考虑使用场景**
   - 网页文本片段解释：2,000 tokens 通常足够
   - 技术文档解释：4,000 - 8,000 tokens
   - 学术论文解释：8,000+ tokens

2. **考虑成本**
   - Token 数越多，API 调用成本越高
   - 根据实际需求平衡功能和成本

3. **考虑响应速度**
   - Token 数越多，生成时间越长
   - 快速响应场景建议使用较小值

## ⚙️ 实际配置示例

### 示例 1: OpenAI GPT-4 标准配置
```
模型: gpt-4
最大 Tokens: 4000
说明: 适合大多数网页文本解释场景
```

### 示例 2: Claude 长文本配置
```
模型: claude-3-sonnet
最大 Tokens: 50000
说明: 适合解释长文档或需要详细分析
```

### 示例 3: 本地模型节省配置
```
模型: llama-3
最大 Tokens: 2000
说明: 本地部署，优先考虑速度
```

## 📝 注意事项

1. **超出限制的处理**
   - 如果输入+输出超过限制，API 会返回错误
   - 建议保守设置，预留缓冲空间

2. **不同接口的差异**
   - 某些兼容接口可能有自己的限制
   - 部署时需要查看具体服务商的文档

3. **动态调整**
   - 可以根据实际使用效果调整配置
   - 插件支持随时修改设置

## 🔗 参考链接

- [OpenAI API 文档](https://platform.openai.com/docs/models)
- [Anthropic Claude 文档](https://docs.anthropic.com/claude/docs)
- [Google Gemini 文档](https://ai.google.dev/docs)
